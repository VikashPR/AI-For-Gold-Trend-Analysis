{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76cda901",
   "metadata": {},
   "source": [
    "### ==========================================\n",
    "### MODULE E: AI Applications - Individual Open Project\n",
    "### Project: Gold Market Trend Analysis using LSTM\n",
    "### Name: Vikash PR\n",
    "### ==========================================\n",
    "\n",
    "**Objectives:**\n",
    "1. Analyze historical gold price data and identify patterns\n",
    "2. Engineer meaningful technical indicators for feature extraction\n",
    "3. Build and train a deep learning model (LSTM) for price prediction\n",
    "4. Evaluate model performance and generate future predictions\n",
    "\n",
    "**Technology Stack:**\n",
    "- Python 3.10+\n",
    "- TensorFlow/Keras for Deep Learning\n",
    "- Pandas & NumPy for Data Processing\n",
    "- Matplotlib, Seaborn & Plotly for Visualization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b73cb1",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import all necessary libraries for data processing, visualization, and deep learning model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38597e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing & Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning & Deep Learning\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Data Fetching\n",
    "import yfinance as yf\n",
    "\n",
    "# Model Saving\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üì¶ TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"üì¶ Pandas Version: {pd.__version__}\")\n",
    "print(f\"üì¶ NumPy Version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58919465",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Dataset\n",
    "\n",
    "We'll fetch gold price data (GC=F - Gold Futures) from Yahoo Finance covering the period from 2013 to present. This provides us with 12+ years of daily OHLCV (Open, High, Low, Close, Volume) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f45694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range for data collection\n",
    "START_DATE = \"2013-01-01\"\n",
    "END_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"üìÖ Fetching Gold Price Data from {START_DATE} to {END_DATE}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Fetch Gold Futures data from Yahoo Finance\n",
    "# GC=F is the ticker symbol for Gold Futures\n",
    "gold_data = yf.download(\"GC=F\", start=START_DATE, end=END_DATE, progress=False)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"\\n‚úÖ Data Successfully Loaded!\")\n",
    "print(f\"üìä Dataset Shape: {gold_data.shape}\")\n",
    "print(f\"üìÖ Date Range: {gold_data.index.min().strftime('%Y-%m-%d')} to {gold_data.index.max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"üìà Total Trading Days: {len(gold_data)}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nüìã First 5 Rows:\")\n",
    "gold_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c749226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last few rows\n",
    "print(\"üìã Last 5 Rows:\")\n",
    "gold_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66466a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed information about the dataset\n",
    "print(\"üìä Dataset Information:\")\n",
    "print(\"=\" * 50)\n",
    "print(gold_data.info())\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"\\nüìà Statistical Summary:\")\n",
    "gold_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7325067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"üîç Missing Values Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "missing_values = gold_data.isnull().sum()\n",
    "missing_percentage = (gold_data.isnull().sum() / len(gold_data)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage (%)': missing_percentage\n",
    "})\n",
    "print(missing_df)\n",
    "print(f\"\\nüìä Total Rows with Missing Data: {gold_data.isnull().any(axis=1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7c3327",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Cleaning\n",
    "\n",
    "In this section, we'll:\n",
    "- Handle missing values using forward/backward fill\n",
    "- Flatten multi-level column headers (if present from yfinance)\n",
    "- Detect and handle outliers in price data\n",
    "- Prepare the data for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe for processing\n",
    "df = gold_data.copy()\n",
    "\n",
    "# Flatten multi-level column headers if present (yfinance sometimes returns multi-level)\n",
    "if isinstance(df.columns, pd.MultiIndex):\n",
    "    df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "# Rename columns for consistency\n",
    "df.columns = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "\n",
    "# We'll use 'Close' as our primary target, drop 'Adj Close' as it's similar\n",
    "df = df.drop('Adj Close', axis=1)\n",
    "\n",
    "print(\"üìä Cleaned Dataset Columns:\", list(df.columns))\n",
    "print(f\"üìà Dataset Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e518d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values using forward fill followed by backward fill\n",
    "print(\"üîß Handling Missing Values...\")\n",
    "print(f\"Before: {df.isnull().sum().sum()} missing values\")\n",
    "\n",
    "# Forward fill (use previous day's value)\n",
    "df = df.ffill()\n",
    "\n",
    "# Backward fill for any remaining NaN at the start\n",
    "df = df.bfill()\n",
    "\n",
    "# Drop any remaining rows with NaN (if any)\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"After: {df.isnull().sum().sum()} missing values\")\n",
    "print(f\"‚úÖ Dataset Shape After Cleaning: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc4fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Detection using IQR method\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"Detect outliers using Interquartile Range method\"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Check outliers in Close price\n",
    "outliers, lower, upper = detect_outliers_iqr(df, 'Close')\n",
    "print(\"üîç Outlier Analysis for Close Price:\")\n",
    "print(f\"   Lower Bound: ${lower:.2f}\")\n",
    "print(f\"   Upper Bound: ${upper:.2f}\")\n",
    "print(f\"   Number of Outliers: {len(outliers)}\")\n",
    "print(f\"   Outlier Percentage: {(len(outliers)/len(df))*100:.2f}%\")\n",
    "\n",
    "# Note: For financial data, we typically keep outliers as they represent real market events\n",
    "print(\"\\nüìù Note: Outliers are kept as they represent real market events (COVID, financial crises, etc.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2365ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw data for reference\n",
    "raw_data_path = 'data/raw/gold_prices_raw.csv'\n",
    "df.to_csv(raw_data_path)\n",
    "print(f\"‚úÖ Raw data saved to: {raw_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c11610",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis and Visualization\n",
    "\n",
    "Let's visualize the gold price data to understand trends, patterns, and volatility over the 12+ year period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c028c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gold Price Time Series Plot\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "# Plot 1: Closing Price Over Time\n",
    "axes[0].plot(df.index, df['Close'], color='gold', linewidth=1.5, label='Close Price')\n",
    "axes[0].set_title('Gold Price (USD/oz) - 2013 to Present', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Price (USD)')\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Mark significant events\n",
    "covid_start = pd.Timestamp('2020-03-01')\n",
    "if covid_start in df.index or covid_start < df.index.max():\n",
    "    axes[0].axvline(x=covid_start, color='red', linestyle='--', alpha=0.7, label='COVID-19')\n",
    "    axes[0].annotate('COVID-19', xy=(covid_start, df['Close'].max()), fontsize=9, color='red')\n",
    "\n",
    "# Plot 2: High and Low Prices\n",
    "axes[1].fill_between(df.index, df['Low'], df['High'], alpha=0.3, color='blue', label='High-Low Range')\n",
    "axes[1].plot(df.index, df['Close'], color='gold', linewidth=1, label='Close')\n",
    "axes[1].set_title('Gold Price Range (High-Low)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Price (USD)')\n",
    "axes[1].legend(loc='upper left')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Trading Volume\n",
    "axes[2].bar(df.index, df['Volume'], color='steelblue', alpha=0.7, width=1)\n",
    "axes[2].set_title('Trading Volume Over Time', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Date')\n",
    "axes[2].set_ylabel('Volume')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/visualizations/gold_price_overview.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Chart saved to: images/visualizations/gold_price_overview.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de6bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Candlestick Chart using Plotly (Last 6 months for clarity)\n",
    "last_6_months = df.last('6M')\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(\n",
    "    x=last_6_months.index,\n",
    "    open=last_6_months['Open'],\n",
    "    high=last_6_months['High'],\n",
    "    low=last_6_months['Low'],\n",
    "    close=last_6_months['Close'],\n",
    "    name='Gold Price'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Gold Price Candlestick Chart (Last 6 Months)',\n",
    "    yaxis_title='Price (USD/oz)',\n",
    "    xaxis_title='Date',\n",
    "    template='plotly_white',\n",
    "    xaxis_rangeslider_visible=False,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb1028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution and Correlation Analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Price Distribution\n",
    "axes[0, 0].hist(df['Close'], bins=50, color='gold', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Gold Close Price Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Price (USD)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(df['Close'].mean(), color='red', linestyle='--', label=f'Mean: ${df[\"Close\"].mean():.2f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Daily Returns Distribution\n",
    "daily_returns = df['Close'].pct_change().dropna() * 100\n",
    "axes[0, 1].hist(daily_returns, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('Daily Returns Distribution (%)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Daily Return (%)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].axvline(0, color='red', linestyle='--')\n",
    "\n",
    "# Box Plot of OHLC Prices\n",
    "axes[1, 0].boxplot([df['Open'], df['High'], df['Low'], df['Close']], \n",
    "                    labels=['Open', 'High', 'Low', 'Close'])\n",
    "axes[1, 0].set_title('OHLC Price Distribution (Box Plot)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Price (USD)')\n",
    "\n",
    "# Correlation Heatmap\n",
    "corr_matrix = df[['Open', 'High', 'Low', 'Close', 'Volume']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='YlOrRd', ax=axes[1, 1], fmt='.3f')\n",
    "axes[1, 1].set_title('Feature Correlation Heatmap', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/visualizations/gold_price_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Chart saved to: images/visualizations/gold_price_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b329264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly and Monthly Analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Add year and month columns for analysis\n",
    "df_analysis = df.copy()\n",
    "df_analysis['Year'] = df_analysis.index.year\n",
    "df_analysis['Month'] = df_analysis.index.month\n",
    "\n",
    "# Yearly Average Price\n",
    "yearly_avg = df_analysis.groupby('Year')['Close'].mean()\n",
    "axes[0].bar(yearly_avg.index, yearly_avg.values, color='gold', edgecolor='black')\n",
    "axes[0].set_title('Average Gold Price by Year', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Year')\n",
    "axes[0].set_ylabel('Average Price (USD)')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Monthly Seasonality\n",
    "monthly_avg = df_analysis.groupby('Month')['Close'].mean()\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "axes[1].bar(range(1, 13), monthly_avg.values, color='steelblue', edgecolor='black')\n",
    "axes[1].set_title('Average Gold Price by Month (Seasonality)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Month')\n",
    "axes[1].set_ylabel('Average Price (USD)')\n",
    "axes[1].set_xticks(range(1, 13))\n",
    "axes[1].set_xticklabels(month_names)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/visualizations/gold_price_seasonality.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Chart saved to: images/visualizations/gold_price_seasonality.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85be7a74",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering - Technical Indicators\n",
    "\n",
    "We'll calculate various technical indicators commonly used in financial analysis:\n",
    "- **Moving Averages (SMA, EMA)**: Trend identification\n",
    "- **RSI (Relative Strength Index)**: Overbought/oversold conditions\n",
    "- **MACD**: Momentum and trend changes\n",
    "- **Bollinger Bands**: Volatility measurement\n",
    "- **Daily Returns & Volatility**: Price momentum indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ea2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for feature engineering\n",
    "df_features = df.copy()\n",
    "\n",
    "# =====================================\n",
    "# 1. Moving Averages (SMA and EMA)\n",
    "# =====================================\n",
    "# Simple Moving Averages\n",
    "df_features['SMA_20'] = df_features['Close'].rolling(window=20).mean()\n",
    "df_features['SMA_50'] = df_features['Close'].rolling(window=50).mean()\n",
    "df_features['SMA_200'] = df_features['Close'].rolling(window=200).mean()\n",
    "\n",
    "# Exponential Moving Average\n",
    "df_features['EMA_20'] = df_features['Close'].ewm(span=20, adjust=False).mean()\n",
    "\n",
    "print(\"‚úÖ Moving Averages calculated: SMA_20, SMA_50, SMA_200, EMA_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4a12b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 2. RSI (Relative Strength Index)\n",
    "# =====================================\n",
    "def calculate_rsi(data, window=14):\n",
    "    \"\"\"Calculate RSI indicator\"\"\"\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "df_features['RSI'] = calculate_rsi(df_features['Close'])\n",
    "print(\"‚úÖ RSI (14-period) calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc51549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 2. RSI (Relative Strength Index)\n",
    "# =====================================\n",
    "def calculate_rsi(data, window=14):\n",
    "    \"\"\"Calculate Relative Strength Index\"\"\"\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    \n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "df_features['RSI'] = calculate_rsi(df_features['Close'], window=14)\n",
    "print(\"‚úÖ RSI (14-day) calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65438ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 3. MACD (Moving Average Convergence Divergence)\n",
    "# =====================================\n",
    "def calculate_macd(data, fast=12, slow=26, signal=9):\n",
    "    \"\"\"Calculate MACD, Signal Line, and Histogram\"\"\"\n",
    "    ema_fast = data.ewm(span=fast, adjust=False).mean()\n",
    "    ema_slow = data.ewm(span=slow, adjust=False).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    signal_line = macd.ewm(span=signal, adjust=False).mean()\n",
    "    histogram = macd - signal_line\n",
    "    return macd, signal_line, histogram\n",
    "\n",
    "df_features['MACD'], df_features['MACD_Signal'], df_features['MACD_Hist'] = calculate_macd(df_features['Close'])\n",
    "print(\"‚úÖ MACD, Signal Line, and Histogram calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259eaced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 4. Bollinger Bands\n",
    "# =====================================\n",
    "def calculate_bollinger_bands(data, window=20, num_std=2):\n",
    "    \"\"\"Calculate Bollinger Bands\"\"\"\n",
    "    sma = data.rolling(window=window).mean()\n",
    "    std = data.rolling(window=window).std()\n",
    "    upper_band = sma + (std * num_std)\n",
    "    lower_band = sma - (std * num_std)\n",
    "    return upper_band, sma, lower_band\n",
    "\n",
    "df_features['BB_Upper'], df_features['BB_Middle'], df_features['BB_Lower'] = calculate_bollinger_bands(df_features['Close'])\n",
    "df_features['BB_Width'] = df_features['BB_Upper'] - df_features['BB_Lower']\n",
    "print(\"‚úÖ Bollinger Bands calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1ddf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 5. Daily Returns and Volatility\n",
    "# =====================================\n",
    "# Daily Returns (percentage change)\n",
    "df_features['Daily_Return'] = df_features['Close'].pct_change() * 100\n",
    "\n",
    "# Rolling Volatility (standard deviation of returns over 20 days)\n",
    "df_features['Volatility_20'] = df_features['Daily_Return'].rolling(window=20).std()\n",
    "\n",
    "# Price Change (absolute)\n",
    "df_features['Price_Change'] = df_features['Close'].diff()\n",
    "\n",
    "# High-Low Range\n",
    "df_features['HL_Range'] = df_features['High'] - df_features['Low']\n",
    "\n",
    "# Open-Close Range\n",
    "df_features['OC_Range'] = df_features['Close'] - df_features['Open']\n",
    "\n",
    "print(\"‚úÖ Daily Returns, Volatility, and Range features calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf6b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 6. Lag Features (Previous day values)\n",
    "# =====================================\n",
    "# Previous close prices (lag features)\n",
    "for lag in [1, 2, 3, 5, 7]:\n",
    "    df_features[f'Close_Lag_{lag}'] = df_features['Close'].shift(lag)\n",
    "\n",
    "print(\"‚úÖ Lag features calculated (1, 2, 3, 5, 7 days)\")\n",
    "\n",
    "# Display all features\n",
    "print(\"\\nüìä Feature Summary:\")\n",
    "print(f\"Total Features: {len(df_features.columns)}\")\n",
    "print(\"\\nFeatures Created:\")\n",
    "for i, col in enumerate(df_features.columns, 1):\n",
    "    print(f\"  {i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Technical Indicators\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 16))\n",
    "\n",
    "# Use last 2 years of data for clearer visualization\n",
    "plot_data = df_features.last('2Y')\n",
    "\n",
    "# Plot 1: Price with Moving Averages\n",
    "axes[0].plot(plot_data.index, plot_data['Close'], label='Close', color='black', linewidth=1.5)\n",
    "axes[0].plot(plot_data.index, plot_data['SMA_20'], label='SMA 20', color='blue', alpha=0.7)\n",
    "axes[0].plot(plot_data.index, plot_data['SMA_50'], label='SMA 50', color='orange', alpha=0.7)\n",
    "axes[0].plot(plot_data.index, plot_data['SMA_200'], label='SMA 200', color='red', alpha=0.7)\n",
    "axes[0].set_title('Gold Price with Moving Averages', fontsize=12, fontweight='bold')\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Price with Bollinger Bands\n",
    "axes[1].plot(plot_data.index, plot_data['Close'], label='Close', color='black', linewidth=1.5)\n",
    "axes[1].fill_between(plot_data.index, plot_data['BB_Upper'], plot_data['BB_Lower'], \n",
    "                     alpha=0.2, color='blue', label='Bollinger Bands')\n",
    "axes[1].plot(plot_data.index, plot_data['BB_Upper'], color='blue', linestyle='--', alpha=0.5)\n",
    "axes[1].plot(plot_data.index, plot_data['BB_Lower'], color='blue', linestyle='--', alpha=0.5)\n",
    "axes[1].set_title('Gold Price with Bollinger Bands', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(loc='upper left')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: RSI\n",
    "axes[2].plot(plot_data.index, plot_data['RSI'], color='purple', linewidth=1.5)\n",
    "axes[2].axhline(y=70, color='red', linestyle='--', alpha=0.7, label='Overbought (70)')\n",
    "axes[2].axhline(y=30, color='green', linestyle='--', alpha=0.7, label='Oversold (30)')\n",
    "axes[2].fill_between(plot_data.index, 70, 100, alpha=0.1, color='red')\n",
    "axes[2].fill_between(plot_data.index, 0, 30, alpha=0.1, color='green')\n",
    "axes[2].set_title('RSI (Relative Strength Index)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylim(0, 100)\n",
    "axes[2].legend(loc='upper left')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: MACD\n",
    "axes[3].plot(plot_data.index, plot_data['MACD'], label='MACD', color='blue', linewidth=1.5)\n",
    "axes[3].plot(plot_data.index, plot_data['MACD_Signal'], label='Signal', color='orange', linewidth=1.5)\n",
    "axes[3].bar(plot_data.index, plot_data['MACD_Hist'], label='Histogram', color='gray', alpha=0.5, width=1)\n",
    "axes[3].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[3].set_title('MACD (Moving Average Convergence Divergence)', fontsize=12, fontweight='bold')\n",
    "axes[3].legend(loc='upper left')\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/visualizations/technical_indicators.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Chart saved to: images/visualizations/technical_indicators.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d14c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values (from rolling calculations)\n",
    "print(f\"üìä Shape before dropping NaN: {df_features.shape}\")\n",
    "df_features = df_features.dropna()\n",
    "print(f\"üìä Shape after dropping NaN: {df_features.shape}\")\n",
    "\n",
    "# Display sample of the feature-engineered dataset\n",
    "print(\"\\nüìã Sample of Feature-Engineered Dataset:\")\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a160e09",
   "metadata": {},
   "source": [
    "## 6. Data Normalization and Scaling\n",
    "\n",
    "Apply MinMaxScaler to normalize all features to the 0-1 range for optimal LSTM training. Neural networks perform better with normalized data as it helps with gradient descent optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf009174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for the model\n",
    "# We'll use a subset of features that are most relevant for prediction\n",
    "feature_columns = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "    'SMA_20', 'SMA_50', 'EMA_20',\n",
    "    'RSI', 'MACD', 'MACD_Signal',\n",
    "    'BB_Upper', 'BB_Lower', 'BB_Width',\n",
    "    'Daily_Return', 'Volatility_20',\n",
    "    'HL_Range', 'OC_Range'\n",
    "]\n",
    "\n",
    "# Create feature matrix\n",
    "data = df_features[feature_columns].values\n",
    "\n",
    "# Store the original Close prices for later inverse transformation\n",
    "close_prices = df_features['Close'].values\n",
    "\n",
    "print(f\"üìä Feature Matrix Shape: {data.shape}\")\n",
    "print(f\"üìã Features Used ({len(feature_columns)}):\")\n",
    "for i, col in enumerate(feature_columns, 1):\n",
    "    print(f\"   {i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74948354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit and transform the data\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Create a separate scaler for the Close price (for inverse transformation)\n",
    "close_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "close_scaler.fit(close_prices.reshape(-1, 1))\n",
    "\n",
    "print(\"‚úÖ Data Normalization Complete!\")\n",
    "print(f\"üìä Scaled Data Shape: {scaled_data.shape}\")\n",
    "print(f\"üìà Value Range: [{scaled_data.min():.4f}, {scaled_data.max():.4f}]\")\n",
    "\n",
    "# Display sample of scaled data\n",
    "print(\"\\nüìã Sample of Scaled Data (first 5 rows, first 5 features):\")\n",
    "print(pd.DataFrame(scaled_data[:5, :5], columns=feature_columns[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d5862d",
   "metadata": {},
   "source": [
    "## 7. Create Sequences for LSTM\n",
    "\n",
    "LSTMs require 3D input: `(samples, timesteps, features)`. We'll create sliding window sequences with a 60-day lookback period, meaning the model will use the past 60 days of data to predict the next day's closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9236c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sequence parameters\n",
    "LOOKBACK = 60  # Number of previous days to use for prediction\n",
    "TARGET_COL = 3  # Index of 'Close' in feature_columns (0-indexed)\n",
    "\n",
    "def create_sequences(data, lookback, target_col):\n",
    "    \"\"\"\n",
    "    Create sequences for LSTM training.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: Scaled feature matrix\n",
    "    - lookback: Number of time steps to look back\n",
    "    - target_col: Column index of the target variable (Close price)\n",
    "    \n",
    "    Returns:\n",
    "    - X: Input sequences (samples, timesteps, features)\n",
    "    - y: Target values (next day's close price)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(lookback, len(data)):\n",
    "        # Input: past 'lookback' days of all features\n",
    "        X.append(data[i-lookback:i])\n",
    "        # Target: next day's Close price (scaled)\n",
    "        y.append(data[i, target_col])\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(scaled_data, LOOKBACK, TARGET_COL)\n",
    "\n",
    "print(f\"‚úÖ Sequences Created!\")\n",
    "print(f\"üìä Input Shape (X): {X.shape} ‚Üí (samples, timesteps, features)\")\n",
    "print(f\"üìä Target Shape (y): {y.shape} ‚Üí (samples,)\")\n",
    "print(f\"\\nüìã Sequence Details:\")\n",
    "print(f\"   - Lookback Window: {LOOKBACK} days\")\n",
    "print(f\"   - Number of Features: {X.shape[2]}\")\n",
    "print(f\"   - Total Sequences: {X.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25738d36",
   "metadata": {},
   "source": [
    "## 8. Train-Test Split\n",
    "\n",
    "Split the data chronologically with 80% for training and 20% for testing. It's crucial to maintain temporal order to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train-test split ratio\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "# Calculate split index\n",
    "split_idx = int(len(X) * TRAIN_RATIO)\n",
    "\n",
    "# Split the data (chronological order maintained)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# Get corresponding dates for visualization later\n",
    "dates = df_features.index[LOOKBACK:]\n",
    "train_dates = dates[:split_idx]\n",
    "test_dates = dates[split_idx:]\n",
    "\n",
    "print(\"‚úÖ Train-Test Split Complete!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Training Set:\")\n",
    "print(f\"   - X_train shape: {X_train.shape}\")\n",
    "print(f\"   - y_train shape: {y_train.shape}\")\n",
    "print(f\"   - Date Range: {train_dates[0].strftime('%Y-%m-%d')} to {train_dates[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"\\nüìä Testing Set:\")\n",
    "print(f\"   - X_test shape: {X_test.shape}\")\n",
    "print(f\"   - y_test shape: {y_test.shape}\")\n",
    "print(f\"   - Date Range: {test_dates[0].strftime('%Y-%m-%d')} to {test_dates[-1].strftime('%Y-%m-%d')}\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nüìà Split Ratio: {TRAIN_RATIO*100:.0f}% Train / {(1-TRAIN_RATIO)*100:.0f}% Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3c8cc7",
   "metadata": {},
   "source": [
    "## 9. Build LSTM Model Architecture\n",
    "\n",
    "We'll build a stacked LSTM model with the following architecture:\n",
    "- **LSTM Layer 1**: 128 units with return_sequences=True + Dropout(0.2)\n",
    "- **LSTM Layer 2**: 64 units + Dropout(0.2)\n",
    "- **Dense Layer**: 32 units with ReLU activation\n",
    "- **Output Layer**: 1 unit (linear activation for regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e4c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Build a stacked LSTM model for gold price prediction.\n",
    "    \n",
    "    Architecture:\n",
    "    - LSTM(128) ‚Üí Dropout(0.2)\n",
    "    - LSTM(64) ‚Üí Dropout(0.2)\n",
    "    - Dense(32, ReLU)\n",
    "    - Dense(1, Linear)\n",
    "    \n",
    "    Parameters:\n",
    "    - input_shape: Tuple of (timesteps, features)\n",
    "    \n",
    "    Returns:\n",
    "    - Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # First LSTM Layer\n",
    "        LSTM(units=128, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Second LSTM Layer\n",
    "        LSTM(units=64, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Dense Layer\n",
    "        Dense(units=32, activation='relu'),\n",
    "        \n",
    "        # Output Layer\n",
    "        Dense(units=1, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # (timesteps, features)\n",
    "model = build_lstm_model(input_shape)\n",
    "\n",
    "# Display model summary\n",
    "print(\"üèóÔ∏è LSTM Model Architecture:\")\n",
    "print(\"=\" * 60)\n",
    "model.summary()\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f648b9",
   "metadata": {},
   "source": [
    "## 10. Train the LSTM Model\n",
    "\n",
    "Train the model with:\n",
    "- **Epochs**: 100 (with early stopping)\n",
    "- **Batch Size**: 32\n",
    "- **Validation Split**: 10% of training data\n",
    "- **Callbacks**: Early Stopping and Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0718352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    # Early Stopping: Stop training if validation loss doesn't improve for 15 epochs\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Model Checkpoint: Save the best model\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/lstm_gold_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"üöÄ Starting Model Training...\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìã Training Configuration:\")\n",
    "print(f\"   - Epochs: {EPOCHS}\")\n",
    "print(f\"   - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   - Validation Split: {VALIDATION_SPLIT*100:.0f}%\")\n",
    "print(f\"   - Early Stopping Patience: 15 epochs\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Model Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cef18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training History\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot Loss\n",
    "axes[0].plot(history.history['loss'], label='Training Loss', color='blue', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss', color='orange', linewidth=2)\n",
    "axes[0].set_title('Model Loss Over Epochs', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss (MSE)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot MAE\n",
    "axes[1].plot(history.history['mae'], label='Training MAE', color='blue', linewidth=2)\n",
    "axes[1].plot(history.history['val_mae'], label='Validation MAE', color='orange', linewidth=2)\n",
    "axes[1].set_title('Model MAE Over Epochs', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/visualizations/training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Chart saved to: images/visualizations/training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f980087e",
   "metadata": {},
   "source": [
    "## 11. Make Predictions\n",
    "\n",
    "Generate predictions on both training and test datasets to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83901992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on training and test sets\n",
    "print(\"üîÆ Generating Predictions...\")\n",
    "\n",
    "# Predictions on training set\n",
    "train_predictions_scaled = model.predict(X_train, verbose=0)\n",
    "\n",
    "# Predictions on test set\n",
    "test_predictions_scaled = model.predict(X_test, verbose=0)\n",
    "\n",
    "print(f\"‚úÖ Predictions Generated!\")\n",
    "print(f\"üìä Training Predictions Shape: {train_predictions_scaled.shape}\")\n",
    "print(f\"üìä Test Predictions Shape: {test_predictions_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d9fc1",
   "metadata": {},
   "source": [
    "## 12. Inverse Transform Predictions\n",
    "\n",
    "Convert the scaled predictions back to original USD price scale for interpretable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864a91f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform predictions to original scale\n",
    "train_predictions = close_scaler.inverse_transform(train_predictions_scaled)\n",
    "test_predictions = close_scaler.inverse_transform(test_predictions_scaled)\n",
    "\n",
    "# Inverse transform actual values\n",
    "y_train_actual = close_scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "y_test_actual = close_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "print(\"‚úÖ Inverse Transformation Complete!\")\n",
    "print(f\"\\nüìä Price Range in Predictions:\")\n",
    "print(f\"   Training Set: ${train_predictions.min():.2f} - ${train_predictions.max():.2f}\")\n",
    "print(f\"   Test Set: ${test_predictions.min():.2f} - ${test_predictions.max():.2f}\")\n",
    "\n",
    "# Display sample predictions vs actual\n",
    "print(\"\\nüìã Sample Test Predictions vs Actual:\")\n",
    "sample_comparison = pd.DataFrame({\n",
    "    'Date': test_dates[:10],\n",
    "    'Actual': y_test_actual[:10].flatten(),\n",
    "    'Predicted': test_predictions[:10].flatten(),\n",
    "    'Difference': (y_test_actual[:10] - test_predictions[:10]).flatten()\n",
    "})\n",
    "sample_comparison['% Error'] = (abs(sample_comparison['Difference']) / sample_comparison['Actual'] * 100)\n",
    "print(sample_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb96b51",
   "metadata": {},
   "source": [
    "## 13. Evaluate Model Performance\n",
    "\n",
    "Calculate and analyze key evaluation metrics:\n",
    "- **RMSE** (Root Mean Square Error)\n",
    "- **MAE** (Mean Absolute Error)\n",
    "- **MAPE** (Mean Absolute Percentage Error)\n",
    "- **R¬≤ Score** (Coefficient of Determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54adf309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mape(actual, predicted):\n",
    "    \"\"\"Calculate Mean Absolute Percentage Error\"\"\"\n",
    "    return np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "\n",
    "def evaluate_model(actual, predicted, set_name=\"\"):\n",
    "    \"\"\"Calculate and return all evaluation metrics\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mape = calculate_mape(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    \n",
    "    return {\n",
    "        'Set': set_name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'MAPE (%)': mape,\n",
    "        'R¬≤ Score': r2\n",
    "    }\n",
    "\n",
    "# Calculate metrics for training and test sets\n",
    "train_metrics = evaluate_model(y_train_actual, train_predictions, \"Training\")\n",
    "test_metrics = evaluate_model(y_test_actual, test_predictions, \"Test\")\n",
    "\n",
    "# Create metrics DataFrame\n",
    "metrics_df = pd.DataFrame([train_metrics, test_metrics])\n",
    "\n",
    "print(\"üìä Model Performance Metrics\")\n",
    "print(\"=\" * 70)\n",
    "print(metrics_df.to_string(index=False))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Performance analysis\n",
    "print(\"\\nüìà Performance Analysis:\")\n",
    "print(f\"   ‚úÖ RMSE (Test): ${test_metrics['RMSE']:.2f} USD\")\n",
    "print(f\"   ‚úÖ MAE (Test): ${test_metrics['MAE']:.2f} USD\")\n",
    "print(f\"   ‚úÖ MAPE (Test): {test_metrics['MAPE (%)']:.2f}%\")\n",
    "print(f\"   ‚úÖ R¬≤ Score (Test): {test_metrics['R¬≤ Score']:.4f}\")\n",
    "\n",
    "# Check against targets\n",
    "print(\"\\nüéØ Performance vs Targets:\")\n",
    "print(f\"   MAE Target (< $20): {'‚úÖ PASS' if test_metrics['MAE'] < 20 else '‚ùå NEEDS IMPROVEMENT'}\")\n",
    "print(f\"   MAPE Target (< 2%): {'‚úÖ PASS' if test_metrics['MAPE (%)'] < 2 else '‚ùå NEEDS IMPROVEMENT'}\")\n",
    "print(f\"   R¬≤ Target (> 0.90): {'‚úÖ PASS' if test_metrics['R¬≤ Score'] > 0.90 else '‚ùå NEEDS IMPROVEMENT'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34917f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend Direction Accuracy\n",
    "def calculate_trend_accuracy(actual, predicted):\n",
    "    \"\"\"Calculate the accuracy of predicting trend direction (up/down)\"\"\"\n",
    "    actual_diff = np.diff(actual.flatten())\n",
    "    predicted_diff = np.diff(predicted.flatten())\n",
    "    \n",
    "    # Check if signs match (both positive or both negative)\n",
    "    correct_direction = np.sum(np.sign(actual_diff) == np.sign(predicted_diff))\n",
    "    total = len(actual_diff)\n",
    "    \n",
    "    return (correct_direction / total) * 100\n",
    "\n",
    "train_trend_acc = calculate_trend_accuracy(y_train_actual, train_predictions)\n",
    "test_trend_acc = calculate_trend_accuracy(y_test_actual, test_predictions)\n",
    "\n",
    "print(\"üìà Trend Direction Accuracy:\")\n",
    "print(f\"   Training Set: {train_trend_acc:.2f}%\")\n",
    "print(f\"   Test Set: {test_trend_acc:.2f}%\")\n",
    "print(\"\\nüìù Note: This measures how often the model correctly predicts whether the price will go up or down.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d17c224",
   "metadata": {},
   "source": [
    "## 14. Visualize Predictions vs Actual Prices\n",
    "\n",
    "Create comprehensive visualizations to compare model predictions with actual gold prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8457a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive prediction visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Full Dataset - Actual vs Predicted\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(train_dates, y_train_actual, label='Actual (Train)', color='blue', alpha=0.7)\n",
    "ax1.plot(train_dates, train_predictions, label='Predicted (Train)', color='cyan', alpha=0.7, linestyle='--')\n",
    "ax1.plot(test_dates, y_test_actual, label='Actual (Test)', color='green', alpha=0.7)\n",
    "ax1.plot(test_dates, test_predictions, label='Predicted (Test)', color='red', alpha=0.7, linestyle='--')\n",
    "ax1.axvline(x=test_dates[0], color='black', linestyle='-', linewidth=2, label='Train/Test Split')\n",
    "ax1.set_title('Gold Price: Actual vs Predicted (Full Dataset)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Price (USD)')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Test Set Only - Zoomed View\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(test_dates, y_test_actual, label='Actual', color='blue', linewidth=2)\n",
    "ax2.plot(test_dates, test_predictions, label='Predicted', color='red', linewidth=2, linestyle='--')\n",
    "ax2.fill_between(test_dates, y_test_actual.flatten(), test_predictions.flatten(), \n",
    "                  alpha=0.2, color='gray', label='Prediction Gap')\n",
    "ax2.set_title('Gold Price: Actual vs Predicted (Test Set)', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Price (USD)')\n",
    "ax2.legend(loc='upper left')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Error Distribution\n",
    "ax3 = axes[1, 0]\n",
    "errors = (y_test_actual - test_predictions).flatten()\n",
    "ax3.hist(errors, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax3.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "ax3.axvline(x=np.mean(errors), color='green', linestyle='--', linewidth=2, label=f'Mean Error: ${np.mean(errors):.2f}')\n",
    "ax3.set_title('Prediction Error Distribution', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Error (Actual - Predicted) USD')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Scatter Plot - Actual vs Predicted\n",
    "ax4 = axes[1, 1]\n",
    "ax4.scatter(y_test_actual, test_predictions, alpha=0.5, color='blue', s=20)\n",
    "min_val = min(y_test_actual.min(), test_predictions.min())\n",
    "max_val = max(y_test_actual.max(), test_predictions.max())\n",
    "ax4.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "ax4.set_title('Actual vs Predicted Prices (Scatter)', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Actual Price (USD)')\n",
    "ax4.set_ylabel('Predicted Price (USD)')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/visualizations/predictions_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Chart saved to: images/visualizations/predictions_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff872d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Plot using Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add actual prices (training)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=train_dates, y=y_train_actual.flatten(),\n",
    "    name='Actual (Train)', mode='lines',\n",
    "    line=dict(color='blue', width=1)\n",
    "))\n",
    "\n",
    "# Add predicted prices (training)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=train_dates, y=train_predictions.flatten(),\n",
    "    name='Predicted (Train)', mode='lines',\n",
    "    line=dict(color='cyan', width=1, dash='dot')\n",
    "))\n",
    "\n",
    "# Add actual prices (test)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_dates, y=y_test_actual.flatten(),\n",
    "    name='Actual (Test)', mode='lines',\n",
    "    line=dict(color='green', width=2)\n",
    "))\n",
    "\n",
    "# Add predicted prices (test)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_dates, y=test_predictions.flatten(),\n",
    "    name='Predicted (Test)', mode='lines',\n",
    "    line=dict(color='red', width=2, dash='dash')\n",
    "))\n",
    "\n",
    "# Add train/test split line\n",
    "fig.add_vline(x=test_dates[0], line_dash=\"solid\", line_color=\"black\", \n",
    "              annotation_text=\"Train/Test Split\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Gold Price Prediction: LSTM Model Results (Interactive)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Price (USD/oz)',\n",
    "    template='plotly_white',\n",
    "    hovermode='x unified',\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a2f02e",
   "metadata": {},
   "source": [
    "## 15. Future Price Prediction\n",
    "\n",
    "Use the last 60 days of available data to predict the next day's gold price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last 60 days of data for future prediction\n",
    "last_60_days = scaled_data[-LOOKBACK:]\n",
    "last_60_days = last_60_days.reshape(1, LOOKBACK, len(feature_columns))\n",
    "\n",
    "# Make prediction\n",
    "next_day_prediction_scaled = model.predict(last_60_days, verbose=0)\n",
    "next_day_prediction = close_scaler.inverse_transform(next_day_prediction_scaled)\n",
    "\n",
    "# Get the last actual price\n",
    "last_actual_price = df_features['Close'].iloc[-1]\n",
    "last_date = df_features.index[-1]\n",
    "next_date = last_date + timedelta(days=1)\n",
    "\n",
    "# Calculate predicted change\n",
    "predicted_change = next_day_prediction[0][0] - last_actual_price\n",
    "predicted_change_pct = (predicted_change / last_actual_price) * 100\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üîÆ FUTURE GOLD PRICE PREDICTION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìÖ Last Available Date: {last_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"üí∞ Last Closing Price: ${last_actual_price:.2f}\")\n",
    "print(f\"\\nüìÖ Prediction Date: {next_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"üéØ Predicted Price: ${next_day_prediction[0][0]:.2f}\")\n",
    "print(f\"\\nüìà Predicted Change: ${predicted_change:.2f} ({predicted_change_pct:+.2f}%)\")\n",
    "print(f\"üìä Trend Direction: {'üìà UP' if predicted_change > 0 else 'üìâ DOWN' if predicted_change < 0 else '‚û°Ô∏è STABLE'}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Confidence context based on model performance\n",
    "print(f\"\\nüìã Model Confidence Context:\")\n",
    "print(f\"   - Based on test set MAPE: {test_metrics['MAPE (%)']:.2f}%\")\n",
    "print(f\"   - Typical prediction range: ${next_day_prediction[0][0] - test_metrics['MAE']:.2f} to ${next_day_prediction[0][0] + test_metrics['MAE']:.2f}\")\n",
    "print(f\"   - R¬≤ Score: {test_metrics['R¬≤ Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddbb933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-day Future Prediction (Next 7 days)\n",
    "def predict_future_days(model, last_sequence, scaler, close_scaler, n_days=7):\n",
    "    \"\"\"\n",
    "    Predict gold prices for the next n days using iterative prediction.\n",
    "    Note: Accuracy decreases for predictions further into the future.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    current_sequence = last_sequence.copy()\n",
    "    \n",
    "    for day in range(n_days):\n",
    "        # Predict next day\n",
    "        next_pred_scaled = model.predict(current_sequence, verbose=0)\n",
    "        predictions.append(next_pred_scaled[0][0])\n",
    "        \n",
    "        # Update sequence for next prediction (simplified - using prediction as next Close)\n",
    "        # Create a new row with the predicted close value\n",
    "        new_row = current_sequence[0, -1, :].copy()\n",
    "        new_row[3] = next_pred_scaled[0][0]  # Update Close column\n",
    "        \n",
    "        # Shift the sequence and add new prediction\n",
    "        current_sequence = np.roll(current_sequence, -1, axis=1)\n",
    "        current_sequence[0, -1, :] = new_row\n",
    "    \n",
    "    # Inverse transform predictions\n",
    "    predictions_array = np.array(predictions).reshape(-1, 1)\n",
    "    predictions_usd = close_scaler.inverse_transform(predictions_array)\n",
    "    \n",
    "    return predictions_usd.flatten()\n",
    "\n",
    "# Predict next 7 days\n",
    "future_predictions = predict_future_days(model, last_60_days, scaler, close_scaler, n_days=7)\n",
    "\n",
    "# Create future dates\n",
    "future_dates = [last_date + timedelta(days=i+1) for i in range(7)]\n",
    "\n",
    "print(\"\\nüìÖ 7-Day Gold Price Forecast:\")\n",
    "print(\"=\" * 50)\n",
    "forecast_df = pd.DataFrame({\n",
    "    'Date': [d.strftime('%Y-%m-%d') for d in future_dates],\n",
    "    'Day': ['Day 1', 'Day 2', 'Day 3', 'Day 4', 'Day 5', 'Day 6', 'Day 7'],\n",
    "    'Predicted Price': [f\"${p:.2f}\" for p in future_predictions],\n",
    "    'Change from Last': [f\"{((p - last_actual_price) / last_actual_price * 100):+.2f}%\" for p in future_predictions]\n",
    "})\n",
    "print(forecast_df.to_string(index=False))\n",
    "print(\"=\" * 50)\n",
    "print(\"\\n‚ö†Ô∏è Note: Predictions become less reliable further into the future.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dbd28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Future Predictions\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add recent historical prices (last 90 days)\n",
    "recent_data = df_features.last('90D')\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=recent_data.index,\n",
    "    y=recent_data['Close'],\n",
    "    name='Historical Prices',\n",
    "    mode='lines',\n",
    "    line=dict(color='blue', width=2)\n",
    "))\n",
    "\n",
    "# Add future predictions\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=future_dates,\n",
    "    y=future_predictions,\n",
    "    name='Predicted Prices',\n",
    "    mode='lines+markers',\n",
    "    line=dict(color='red', width=2, dash='dash'),\n",
    "    marker=dict(size=10, symbol='diamond')\n",
    "))\n",
    "\n",
    "# Add vertical line at last known date\n",
    "fig.add_vline(x=last_date, line_dash=\"solid\", line_color=\"gray\",\n",
    "              annotation_text=\"Last Known Price\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Gold Price: Historical & 7-Day Forecast',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Price (USD/oz)',\n",
    "    template='plotly_white',\n",
    "    hovermode='x unified',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45177db",
   "metadata": {},
   "source": [
    "## 16. Save Trained Model\n",
    "\n",
    "Save the trained LSTM model and the scaler objects for future inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model in both formats\n",
    "model_path_h5 = 'models/lstm_gold_model.h5'\n",
    "model_path_keras = 'models/lstm_gold_model.keras'\n",
    "\n",
    "# Save in H5 format (legacy format)\n",
    "model.save(model_path_h5)\n",
    "print(f\"‚úÖ Model saved to: {model_path_h5}\")\n",
    "\n",
    "# Save in Keras format (recommended for TF 2.x)\n",
    "model.save(model_path_keras)\n",
    "print(f\"‚úÖ Model saved to: {model_path_keras}\")\n",
    "\n",
    "# Save the scalers using joblib\n",
    "scaler_path = 'models/feature_scaler.pkl'\n",
    "close_scaler_path = 'models/close_scaler.pkl'\n",
    "\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"‚úÖ Feature scaler saved to: {scaler_path}\")\n",
    "\n",
    "joblib.dump(close_scaler, close_scaler_path)\n",
    "print(f\"‚úÖ Close scaler saved to: {close_scaler_path}\")\n",
    "\n",
    "# Save feature columns for reference\n",
    "feature_info = {\n",
    "    'feature_columns': feature_columns,\n",
    "    'lookback': LOOKBACK,\n",
    "    'target_col': TARGET_COL\n",
    "}\n",
    "joblib.dump(feature_info, 'models/feature_info.pkl')\n",
    "print(f\"‚úÖ Feature info saved to: models/feature_info.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8685dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "processed_data_path = 'data/processed/gold_prices_features.csv'\n",
    "df_features.to_csv(processed_data_path)\n",
    "print(f\"‚úÖ Processed data saved to: {processed_data_path}\")\n",
    "\n",
    "# Display saved files summary\n",
    "print(\"\\nüìÅ Saved Files Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"üìÇ models/\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ lstm_gold_model.h5\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ lstm_gold_model.keras\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ feature_scaler.pkl\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ close_scaler.pkl\")\n",
    "print(\"   ‚îî‚îÄ‚îÄ feature_info.pkl\")\n",
    "print(\"üìÇ data/\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ raw/gold_prices_raw.csv\")\n",
    "print(\"   ‚îî‚îÄ‚îÄ processed/gold_prices_features.csv\")\n",
    "print(\"üìÇ images/visualizations/\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ gold_price_overview.png\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ gold_price_distribution.png\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ gold_price_seasonality.png\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ technical_indicators.png\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ training_history.png\")\n",
    "print(\"   ‚îî‚îÄ‚îÄ predictions_analysis.png\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356ceb00",
   "metadata": {},
   "source": [
    "## 17. Ethical Considerations & Responsible AI\n",
    "\n",
    "### 7.1 Bias and Fairness\n",
    "- **Data Bias:** Historical data may not represent future market conditions. The model is trained on 2013-2025 data which may not capture all market scenarios.\n",
    "- **Model Bias:** LSTM may overfit to specific market regimes (bull/bear markets).\n",
    "- **Mitigation:** Regular model retraining, ensemble approaches, and continuous monitoring are recommended.\n",
    "\n",
    "### 7.2 Dataset Limitations\n",
    "- Does not include all market-influencing factors (news sentiment, geopolitical events, interest rates)\n",
    "- Historical patterns may not repeat in future markets\n",
    "- Missing data during market holidays affects continuity\n",
    "\n",
    "### 7.3 Responsible Use of AI\n",
    "‚ö†Ô∏è **Important Disclaimers:**\n",
    "- This is an **educational project**, NOT financial advice\n",
    "- Predictions should NOT be solely relied upon for investment decisions\n",
    "- Always consult qualified financial advisors for investment choices\n",
    "- Past performance does NOT guarantee future results\n",
    "- The model has inherent uncertainty and errors\n",
    "\n",
    "### 7.4 AI Tool Usage Declaration\n",
    "- AI tools (GitHub Copilot) used for code assistance\n",
    "- All code logic and analysis performed by the student\n",
    "- Model results require human interpretation and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ba12c0",
   "metadata": {},
   "source": [
    "## 18. Conclusion & Future Scope\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Model Performance:** The LSTM model successfully captured temporal patterns in gold price data, achieving competitive metrics on the test set.\n",
    "\n",
    "2. **Technical Indicators:** Feature engineering with moving averages, RSI, MACD, and Bollinger Bands improved the model's ability to understand market dynamics.\n",
    "\n",
    "3. **Pattern Recognition:** The model demonstrates ability to follow overall price trends and identify major turning points.\n",
    "\n",
    "### Future Improvements\n",
    "\n",
    "1. **External Data Integration:**\n",
    "   - Include macroeconomic indicators (interest rates, inflation)\n",
    "   - Add sentiment analysis from financial news\n",
    "   - Incorporate USD index and other correlated assets\n",
    "\n",
    "2. **Model Enhancements:**\n",
    "   - Implement attention mechanisms (Transformer architecture)\n",
    "   - Ensemble multiple models for robust predictions\n",
    "   - Add bidirectional LSTM layers\n",
    "   - Experiment with different lookback windows\n",
    "\n",
    "3. **Real-time Deployment:**\n",
    "   - Build API for real-time predictions\n",
    "   - Implement automated data pipeline\n",
    "   - Create interactive dashboard for monitoring\n",
    "\n",
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d498b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä PROJECT SUMMARY: AI-Powered Gold Price Trend Analysis & Prediction\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìà Dataset Information:\")\n",
    "print(f\"   ‚Ä¢ Total Data Points: {len(df_features)}\")\n",
    "print(f\"   ‚Ä¢ Date Range: {df_features.index[0].strftime('%Y-%m-%d')} to {df_features.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"   ‚Ä¢ Features Used: {len(feature_columns)}\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è Model Architecture:\")\n",
    "print(f\"   ‚Ä¢ Type: Stacked LSTM Neural Network\")\n",
    "print(f\"   ‚Ä¢ Layers: LSTM(128) ‚Üí LSTM(64) ‚Üí Dense(32) ‚Üí Dense(1)\")\n",
    "print(f\"   ‚Ä¢ Lookback Window: {LOOKBACK} days\")\n",
    "print(f\"   ‚Ä¢ Total Parameters: {model.count_params():,}\")\n",
    "\n",
    "print(\"\\nüìä Performance Metrics (Test Set):\")\n",
    "print(f\"   ‚Ä¢ RMSE: ${test_metrics['RMSE']:.2f}\")\n",
    "print(f\"   ‚Ä¢ MAE: ${test_metrics['MAE']:.2f}\")\n",
    "print(f\"   ‚Ä¢ MAPE: {test_metrics['MAPE (%)']:.2f}%\")\n",
    "print(f\"   ‚Ä¢ R¬≤ Score: {test_metrics['R¬≤ Score']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Trend Accuracy: {test_trend_acc:.2f}%\")\n",
    "\n",
    "print(\"\\nüîÆ Latest Prediction:\")\n",
    "print(f\"   ‚Ä¢ Last Known Price: ${last_actual_price:.2f} ({last_date.strftime('%Y-%m-%d')})\")\n",
    "print(f\"   ‚Ä¢ Next Day Prediction: ${next_day_prediction[0][0]:.2f}\")\n",
    "print(f\"   ‚Ä¢ Predicted Change: {predicted_change_pct:+.2f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ Project completed successfully!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094461a0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö References\n",
    "\n",
    "1. Hochreiter, S., & Schmidhuber, J. (1997). Long Short-Term Memory. *Neural Computation*.\n",
    "2. Yahoo Finance - Gold Futures Historical Data (GC=F)\n",
    "3. TensorFlow/Keras Documentation - https://www.tensorflow.org/\n",
    "4. Technical Analysis Indicators - Investopedia\n",
    "\n",
    "---\n",
    "\n",
    "## üë§ Author Information\n",
    "\n",
    "- **Module:** E - AI Applications\n",
    "- **Project Type:** Individual Open Project\n",
    "- **Track:** Financial AI / Time Series Prediction\n",
    "\n",
    "---\n",
    "\n",
    "*Last Updated: January 2026*\n",
    "\n",
    "‚ö†Ô∏è **Disclaimer:** This notebook is for educational purposes only. The predictions and analyses provided should not be used as financial advice. Always consult with qualified financial professionals before making investment decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
